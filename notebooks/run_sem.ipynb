{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-18T05:31:28.940843Z",
     "start_time": "2024-07-18T05:31:28.932332Z"
    }
   },
   "source": [
    "from src import sem_functions, city_functions, expert_functions\n",
    "import importlib\n",
    "\n",
    "importlib.reload(sem_functions)\n",
    "\n",
    "from src.sem_functions import *\n",
    "from src.city_functions import *\n",
    "from src.expert_functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gzip\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.sem_functions' from '/Users/katharina/Documents/PhD/Scripts_Paper_1/label-uncertainty-so2sat/src/sem_functions.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T05:31:31.077446Z",
     "start_time": "2024-07-18T05:31:30.850051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import csv \n",
    "\n",
    "one_hot_16 = pd.read_csv('../data/one_hot_16.csv').to_numpy()\n",
    "one_hot_c_16 = pd.read_csv('../data/one_hot_c_16.csv')\n",
    "votes_16 = pd.read_csv('../data/votes_16.csv').to_numpy()"
   ],
   "id": "c7022303d475a283",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Full Dataset",
   "id": "5e3674e368bef09e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T05:39:13.163183Z",
     "start_time": "2024-07-18T05:31:33.880196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# run sem on full dataset\n",
    "\n",
    "sem_full = sem_fit_var(one_hot_16, K=16, max_iter=20, rtol=1e-3, restarts=5)"
   ],
   "id": "c321eeec0acf359f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "Loss: -554658.669029\n",
      "Loss: -553255.902614\n",
      "Loss: -552875.325147\n",
      "better loss on iteration 0: -552875.3251473000\n",
      "iteration 1\n",
      "Loss: -554634.621013\n",
      "Loss: -553405.329578\n",
      "Loss: -552868.309576\n",
      "better loss on iteration 1: -552868.3095760166\n",
      "iteration 2\n",
      "Loss: -554648.912238\n",
      "Loss: -553182.846556\n",
      "Loss: -552835.757891\n",
      "better loss on iteration 2: -552835.7578910640\n",
      "iteration 3\n",
      "Loss: -554634.757099\n",
      "Loss: -553308.477523\n",
      "Loss: -552810.603587\n",
      "better loss on iteration 3: -552810.6035872988\n",
      "iteration 4\n",
      "Loss: -554708.202686\n",
      "Loss: -553315.504772\n",
      "Loss: -552894.884581\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T05:42:32.010947Z",
     "start_time": "2024-07-18T05:42:19.233050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# extract parameters\n",
    "\n",
    "pi_full = sem_full[1]\n",
    "theta_full = sem_full[2]\n",
    "tau_full = e_step_nozerocorrection(one_hot_16, pi_full, theta_full)"
   ],
   "id": "c92871c7628af2e0",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Per City ",
   "id": "8e7450053f94c627"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T05:42:33.487899Z",
     "start_time": "2024-07-18T05:42:33.483934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "city_list = ['berlin', 'cologne', 'london', 'madrid',\n",
    "             'milan', 'munich', 'paris', 'rome', 'zurich']"
   ],
   "id": "aa5c3eb36ba5d47a",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T05:52:07.921358Z",
     "start_time": "2024-07-18T05:42:40.978345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# run sem for instances from each city separately\n",
    "\n",
    "sem_city = [sem_fit_var_per_city(city, data=one_hot_c_16,\n",
    "                                 K=16, restarts=5, rtol=1e-3, max_iter=20) for city in city_list]"
   ],
   "id": "61160e2eea55843d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "Loss: -84071.601424\n",
      "Loss: -83693.252366\n",
      "Loss: -83538.341951\n",
      "Loss: -83533.057230\n",
      "better loss on iteration 0: -83533.0572303410\n",
      "iteration 1\n",
      "Loss: -84072.256054\n",
      "Loss: -83687.920996\n",
      "Loss: -83552.052393\n",
      "Loss: -83534.931309\n",
      "iteration 2\n",
      "Loss: -84073.290123\n",
      "Loss: -83679.812310\n",
      "Loss: -83565.660628\n",
      "Loss: -83539.839231\n",
      "iteration 3\n",
      "Loss: -84071.795523\n",
      "Loss: -83671.784042\n",
      "Loss: -83555.293054\n",
      "Loss: -83537.448776\n",
      "iteration 4\n",
      "Loss: -84073.926415\n",
      "Loss: -83666.499348\n",
      "Loss: -83547.245725\n",
      "Loss: -83534.908639\n",
      "iteration 0\n",
      "Loss: -66833.482216\n",
      "Loss: -66775.195120\n",
      "Loss: -66738.403928\n",
      "better loss on iteration 0: -66738.4039278157\n",
      "iteration 1\n",
      "Loss: -66833.209449\n",
      "Loss: -66774.489583\n",
      "Loss: -66741.984550\n",
      "iteration 2\n",
      "Loss: -66846.000862\n",
      "Loss: -66775.320776\n",
      "Loss: -66750.137395\n",
      "iteration 3\n",
      "Loss: -66833.177261\n",
      "Loss: -66776.160713\n",
      "Loss: -66748.275075\n",
      "iteration 4\n",
      "Loss: -66843.159974\n",
      "Loss: -66771.226592\n",
      "Loss: -66747.026384\n",
      "iteration 0\n",
      "Loss: -112906.177929\n",
      "Loss: -112874.363952\n",
      "Loss: -112871.313394\n",
      "better loss on iteration 0: -112871.3133943783\n",
      "iteration 1\n",
      "Loss: -112891.277795\n",
      "Loss: -112873.468861\n",
      "Loss: -112868.482662\n",
      "better loss on iteration 1: -112868.4826622216\n",
      "iteration 2\n",
      "Loss: -112891.869385\n",
      "Loss: -112873.486876\n",
      "Loss: -112866.128586\n",
      "better loss on iteration 2: -112866.1285860912\n",
      "iteration 3\n",
      "Loss: -112902.381298\n",
      "Loss: -112876.063763\n",
      "Loss: -112871.932352\n",
      "iteration 4\n",
      "Loss: -112891.010966\n",
      "Loss: -112887.818482\n",
      "Loss: -112868.019900\n",
      "iteration 0\n",
      "Loss: -57442.499160\n",
      "Loss: -57420.288420\n",
      "Loss: -57427.003412\n",
      "better loss on iteration 0: -57427.0034122674\n",
      "iteration 1\n",
      "Loss: -57359.393325\n",
      "Loss: -57460.864370\n",
      "Loss: -57402.610909\n",
      "Loss: -57436.092578\n",
      "iteration 2\n",
      "Loss: -57417.876089\n",
      "Loss: -57390.567241\n",
      "Loss: -57430.144340\n",
      "iteration 3\n",
      "Loss: -57446.852303\n",
      "Loss: -57417.690199\n",
      "Loss: -57397.329486\n",
      "better loss on iteration 3: -57397.3294864216\n",
      "iteration 4\n",
      "Loss: -57440.056816\n",
      "Loss: -57436.004985\n",
      "Loss: -57352.879146\n",
      "Loss: -57406.468957\n",
      "iteration 0\n",
      "Loss: -9085.127235\n",
      "Loss: -9087.144507\n",
      "Loss: -9085.085141\n",
      "better loss on iteration 0: -9085.0851407592\n",
      "iteration 1\n",
      "Loss: -9085.788664\n",
      "Loss: -9086.625730\n",
      "Loss: -9086.466683\n",
      "iteration 2\n",
      "Loss: -9085.862501\n",
      "Loss: -9085.196340\n",
      "Loss: -9085.674828\n",
      "iteration 3\n",
      "Loss: -9086.867748\n",
      "Loss: -9086.148355\n",
      "Loss: -9086.405871\n",
      "iteration 4\n",
      "Loss: -9085.206255\n",
      "Loss: -9084.581744\n",
      "Loss: -9085.995981\n",
      "iteration 0\n",
      "Loss: -31804.728915\n",
      "Loss: -31805.988088\n",
      "Loss: -31804.347169\n",
      "better loss on iteration 0: -31804.3471691613\n",
      "iteration 1\n",
      "Loss: -31804.728915\n",
      "Loss: -31803.431231\n",
      "Loss: -31802.741055\n",
      "better loss on iteration 1: -31802.7410554373\n",
      "iteration 2\n",
      "Loss: -31806.675208\n",
      "Loss: -31802.741055\n",
      "Loss: -31802.806358\n",
      "iteration 3\n",
      "Loss: -31804.347169\n",
      "Loss: -31804.150694\n",
      "Loss: -31804.150694\n",
      "iteration 4\n",
      "Loss: -31804.347169\n",
      "Loss: -31803.964149\n",
      "Loss: -31805.772536\n",
      "iteration 0\n",
      "Loss: -47116.459353\n",
      "Loss: -46963.929104\n",
      "Loss: -47358.568295\n",
      "Loss: -46917.924249\n",
      "Loss: -47105.686209\n",
      "Loss: -47182.651471\n",
      "Loss: -47388.933207\n",
      "Loss: -47166.192674\n",
      "Loss: -47072.677053\n",
      "Loss: -46993.936681\n",
      "Loss: -47152.995208\n",
      "Loss: -47246.725112\n",
      "Loss: -47373.470174\n",
      "Loss: -47254.818341\n",
      "Loss: -47321.165929\n",
      "Loss: -47266.623312\n",
      "Loss: -47338.333776\n",
      "Loss: -47213.120955\n",
      "Loss: -47362.018014\n",
      "Loss: -47236.853046\n",
      "better loss on iteration 0: -47236.8530462968\n",
      "iteration 1\n",
      "Loss: -47111.570788\n",
      "Loss: -47104.572493\n",
      "Loss: -47172.586416\n",
      "Loss: -47344.252461\n",
      "Loss: -47295.368962\n",
      "Loss: -47328.043633\n",
      "iteration 2\n",
      "Loss: -47476.301325\n",
      "Loss: -46457.134826\n",
      "Loss: -47201.439026\n",
      "Loss: -46945.194247\n",
      "Loss: -47316.360194\n",
      "Loss: -46917.703828\n",
      "Loss: -47205.952727\n",
      "Loss: -47236.393283\n",
      "better loss on iteration 2: -47236.3932829253\n",
      "iteration 3\n",
      "Loss: -47393.151378\n",
      "Loss: -46834.642850\n",
      "Loss: -47210.074020\n",
      "Loss: -46960.190108\n",
      "Loss: -47204.970950\n",
      "Loss: -46762.755171\n",
      "Loss: -47276.864601\n",
      "Loss: -47084.487964\n",
      "Loss: -47186.012099\n",
      "Loss: -47215.448852\n",
      "better loss on iteration 3: -47215.4488522118\n",
      "iteration 4\n",
      "Loss: -47329.213787\n",
      "Loss: -46757.417819\n",
      "Loss: -47252.847388\n",
      "Loss: -47393.575483\n",
      "Loss: -47099.612993\n",
      "Loss: -47312.944034\n",
      "Loss: -47024.501450\n",
      "Loss: -47281.303723\n",
      "Loss: -47307.804071\n",
      "iteration 0\n",
      "Loss: -19384.738293\n",
      "Loss: -19349.631870\n",
      "Loss: -19347.533797\n",
      "better loss on iteration 0: -19347.5337966090\n",
      "iteration 1\n",
      "Loss: -19386.108869\n",
      "Loss: -19350.217880\n",
      "Loss: -19346.179390\n",
      "better loss on iteration 1: -19346.1793897163\n",
      "iteration 2\n",
      "Loss: -19388.016126\n",
      "Loss: -19348.493524\n",
      "Loss: -19346.493873\n",
      "iteration 3\n",
      "Loss: -19387.844734\n",
      "Loss: -19348.951467\n",
      "Loss: -19348.282296\n",
      "iteration 4\n",
      "Loss: -19383.329589\n",
      "Loss: -19348.639952\n",
      "Loss: -19346.902369\n",
      "iteration 0\n",
      "Loss: -15027.382337\n",
      "Loss: -15008.785477\n",
      "Loss: -15015.054137\n",
      "better loss on iteration 0: -15015.0541370836\n",
      "iteration 1\n",
      "Loss: -15037.699737\n",
      "Loss: -15034.513380\n",
      "Loss: -15036.609649\n",
      "iteration 2\n",
      "Loss: -15042.994662\n",
      "Loss: -15073.630498\n",
      "Loss: -15008.891004\n",
      "Loss: -15030.710891\n",
      "Loss: -15032.395490\n",
      "iteration 3\n",
      "Loss: -15008.007269\n",
      "Loss: -15016.683533\n",
      "Loss: -15018.989572\n",
      "iteration 4\n",
      "Loss: -15028.559829\n",
      "Loss: -15001.737428\n",
      "Loss: -15019.896823\n",
      "Loss: -15019.664256\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Per Expert",
   "id": "9b03b65d1cc68d37"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T05:54:01.380468Z",
     "start_time": "2024-07-18T05:54:01.268328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create expert-specific dataframes: df_1 -> exclude annotations from expert 1\n",
    "\n",
    "one_hot_experts = expert_data(votes_16, one_hot_16)"
   ],
   "id": "171dd1a415aa7fe9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df  0  done.\n",
      "df  1  done.\n",
      "df  2  done.\n",
      "df  3  done.\n",
      "df  4  done.\n",
      "df  5  done.\n",
      "df  6  done.\n",
      "df  7  done.\n",
      "df  8  done.\n",
      "df  9  done.\n",
      "df  10  done.\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T07:13:30.087873Z",
     "start_time": "2024-07-18T05:54:04.661178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# run sem for each expert-specific dataframe \n",
    "\n",
    "sem_experts = expert_sem(one_hot_experts, K=16, rtol=1e-3, max_iter=20, restarts=5)"
   ],
   "id": "e1bc010f8a836d15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exclude expert  0\n",
      "iteration 0\n",
      "Loss: -524614.223151\n",
      "Loss: -524339.019640\n",
      "better loss on iteration 0: -524339.0196399577\n",
      "iteration 1\n",
      "Loss: -524740.788038\n",
      "Loss: -524299.525006\n",
      "better loss on iteration 1: -524299.5250062665\n",
      "iteration 2\n",
      "Loss: -524637.012183\n",
      "Loss: -524303.201023\n",
      "iteration 3\n",
      "Loss: -524707.953824\n",
      "Loss: -524187.536788\n",
      "better loss on iteration 3: -524187.5367879105\n",
      "iteration 4\n",
      "Loss: -524696.791959\n",
      "Loss: -524247.932230\n",
      "exclude expert  1\n",
      "iteration 0\n",
      "Loss: -541844.766157\n",
      "Loss: -541148.068845\n",
      "Loss: -540970.151069\n",
      "better loss on iteration 0: -540970.1510694962\n",
      "iteration 1\n",
      "Loss: -541828.199839\n",
      "Loss: -541133.386859\n",
      "Loss: -540978.432932\n",
      "iteration 2\n",
      "Loss: -541905.391967\n",
      "Loss: -541253.216849\n",
      "Loss: -540960.676457\n",
      "better loss on iteration 2: -540960.6764566137\n",
      "iteration 3\n",
      "Loss: -541907.253459\n",
      "Loss: -541216.107018\n",
      "Loss: -540937.546437\n",
      "better loss on iteration 3: -540937.5464369303\n",
      "iteration 4\n",
      "Loss: -541882.303844\n",
      "Loss: -541228.113757\n",
      "Loss: -540973.864943\n",
      "exclude expert  2\n",
      "iteration 0\n",
      "Loss: -539118.365191\n",
      "Loss: -538689.366346\n",
      "better loss on iteration 0: -538689.3663455761\n",
      "iteration 1\n",
      "Loss: -539104.706173\n",
      "Loss: -538630.333994\n",
      "better loss on iteration 1: -538630.3339939046\n",
      "iteration 2\n",
      "Loss: -539064.581793\n",
      "Loss: -538641.610536\n",
      "iteration 3\n",
      "Loss: -539082.999951\n",
      "Loss: -538585.015216\n",
      "better loss on iteration 3: -538585.0152164458\n",
      "iteration 4\n",
      "Loss: -539128.744342\n",
      "Loss: -538742.985049\n",
      "exclude expert  3\n",
      "iteration 0\n",
      "Loss: -539250.196590\n",
      "Loss: -538541.188812\n",
      "Loss: -538353.664281\n",
      "better loss on iteration 0: -538353.6642812231\n",
      "iteration 1\n",
      "Loss: -539250.315866\n",
      "Loss: -538564.247106\n",
      "Loss: -538360.378053\n",
      "iteration 2\n",
      "Loss: -539325.372975\n",
      "Loss: -538630.216669\n",
      "Loss: -538332.918720\n",
      "better loss on iteration 2: -538332.9187196799\n",
      "iteration 3\n",
      "Loss: -539290.071749\n",
      "Loss: -538532.820612\n",
      "Loss: -538266.174460\n",
      "better loss on iteration 3: -538266.1744601092\n",
      "iteration 4\n",
      "Loss: -539282.336527\n",
      "Loss: -538624.245723\n",
      "Loss: -538249.449875\n",
      "better loss on iteration 4: -538249.4498747005\n",
      "exclude expert  4\n",
      "iteration 0\n",
      "Loss: -531398.594041\n",
      "Loss: -530968.266403\n",
      "better loss on iteration 0: -530968.2664030661\n",
      "iteration 1\n",
      "Loss: -531406.399805\n",
      "Loss: -531013.055740\n",
      "iteration 2\n",
      "Loss: -531364.128449\n",
      "Loss: -530960.227581\n",
      "better loss on iteration 2: -530960.2275811781\n",
      "iteration 3\n",
      "Loss: -531416.216133\n",
      "Loss: -531069.943680\n",
      "iteration 4\n",
      "Loss: -531405.373327\n",
      "Loss: -531018.420169\n",
      "exclude expert  5\n",
      "iteration 0\n",
      "Loss: -534988.452259\n",
      "Loss: -533798.023454\n",
      "Loss: -533550.953841\n",
      "better loss on iteration 0: -533550.9538409351\n",
      "iteration 1\n",
      "Loss: -535003.023134\n",
      "Loss: -533847.571757\n",
      "Loss: -533558.890455\n",
      "iteration 2\n",
      "Loss: -535030.792447\n",
      "Loss: -533805.166630\n",
      "Loss: -533542.648528\n",
      "better loss on iteration 2: -533542.6485282602\n",
      "iteration 3\n",
      "Loss: -535030.508016\n",
      "Loss: -533803.324586\n",
      "Loss: -533578.117549\n",
      "iteration 4\n",
      "Loss: -535087.411070\n",
      "Loss: -533735.700707\n",
      "Loss: -533515.080272\n",
      "better loss on iteration 4: -533515.0802720311\n",
      "exclude expert  6\n",
      "iteration 0\n",
      "Loss: -535256.872780\n",
      "Loss: -533935.677171\n",
      "Loss: -533496.319603\n",
      "better loss on iteration 0: -533496.3196034017\n",
      "iteration 1\n",
      "Loss: -535144.396074\n",
      "Loss: -533807.039467\n",
      "Loss: -533439.871656\n",
      "better loss on iteration 1: -533439.8716563478\n",
      "iteration 2\n",
      "Loss: -535162.589091\n",
      "Loss: -533908.024847\n",
      "Loss: -533409.776629\n",
      "better loss on iteration 2: -533409.7766285816\n",
      "iteration 3\n",
      "Loss: -535191.999696\n",
      "Loss: -533898.046081\n",
      "Loss: -533462.027642\n",
      "iteration 4\n",
      "Loss: -535201.552156\n",
      "Loss: -533893.450909\n",
      "Loss: -533531.562396\n",
      "exclude expert  7\n",
      "iteration 0\n",
      "Loss: -533286.006204\n",
      "Loss: -532438.448115\n",
      "Loss: -532247.352667\n",
      "better loss on iteration 0: -532247.3526668918\n",
      "iteration 1\n",
      "Loss: -533310.899694\n",
      "Loss: -532469.143558\n",
      "Loss: -532283.368411\n",
      "iteration 2\n",
      "Loss: -533336.109291\n",
      "Loss: -532475.219468\n",
      "Loss: -532265.349679\n",
      "iteration 3\n",
      "Loss: -533263.316808\n",
      "Loss: -532464.566148\n",
      "Loss: -532335.325696\n",
      "iteration 4\n",
      "Loss: -533263.431526\n",
      "Loss: -532477.327434\n",
      "Loss: -532251.971434\n",
      "exclude expert  8\n",
      "iteration 0\n",
      "Loss: -540522.959835\n",
      "Loss: -539922.341200\n",
      "Loss: -539759.105947\n",
      "better loss on iteration 0: -539759.1059467926\n",
      "iteration 1\n",
      "Loss: -540492.484857\n",
      "Loss: -539017.278025\n",
      "Loss: -538143.137608\n",
      "Loss: -537890.518963\n",
      "better loss on iteration 1: -537890.5189631408\n",
      "iteration 2\n",
      "Loss: -540562.038160\n",
      "Loss: -539867.406376\n",
      "Loss: -539789.527539\n",
      "iteration 3\n",
      "Loss: -540555.821377\n",
      "Loss: -538996.039176\n",
      "Loss: -538136.566746\n",
      "Loss: -537807.298224\n",
      "better loss on iteration 3: -537807.2982235957\n",
      "iteration 4\n",
      "Loss: -540539.852529\n",
      "Loss: -539024.454995\n",
      "Loss: -538170.100747\n",
      "Loss: -537840.476845\n",
      "exclude expert  9\n",
      "iteration 0\n",
      "Loss: -537878.541533\n",
      "Loss: -536741.982803\n",
      "Loss: -536576.258082\n",
      "better loss on iteration 0: -536576.2580815470\n",
      "iteration 1\n",
      "Loss: -537868.119906\n",
      "Loss: -536744.325481\n",
      "Loss: -536580.995206\n",
      "iteration 2\n",
      "Loss: -537852.174222\n",
      "Loss: -536709.807855\n",
      "Loss: -536614.221775\n",
      "iteration 3\n",
      "Loss: -537860.215128\n",
      "Loss: -536707.645928\n",
      "Loss: -536612.837218\n",
      "iteration 4\n",
      "Loss: -537871.413911\n",
      "Loss: -536739.763251\n",
      "Loss: -536620.150797\n",
      "exclude expert  10\n",
      "iteration 0\n",
      "Loss: -540298.445990\n",
      "Loss: -538933.417337\n",
      "Loss: -538847.215456\n",
      "better loss on iteration 0: -538847.2154556828\n",
      "iteration 1\n",
      "Loss: -540339.146249\n",
      "Loss: -538850.839841\n",
      "Loss: -538796.031852\n",
      "better loss on iteration 1: -538796.0318519813\n",
      "iteration 2\n",
      "Loss: -540355.523372\n",
      "Loss: -539018.225921\n",
      "Loss: -538820.752147\n",
      "iteration 3\n",
      "Loss: -540396.615204\n",
      "Loss: -538891.254213\n",
      "Loss: -538856.674748\n",
      "iteration 4\n",
      "Loss: -540373.079696\n",
      "Loss: -538916.762783\n",
      "Loss: -538817.302043\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T07:15:46.801533Z",
     "start_time": "2024-07-18T07:13:35.662261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save results to lists\n",
    "\n",
    "pi_experts=[]\n",
    "theta_experts=[]\n",
    "tau_experts_org=[]\n",
    "tau_experts=[]\n",
    "\n",
    "j=0\n",
    "for sem in sem_experts:\n",
    "    pi_experts.append(sem[1])\n",
    "    theta_experts.append(sem[2])\n",
    "    tau_experts_org.append(sem[4])\n",
    "    tau_experts.append(e_step_nozerocorrection(one_hot_experts[j], sem[1], sem[2]))\n",
    "    j=j+1"
   ],
   "id": "dca4fd26398e6402",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T07:17:37.934482Z",
     "start_time": "2024-07-18T07:17:32.406248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save results to pickle \n",
    "\n",
    "with gzip.open('../data/sem_experts.pkl', 'wb') as file:\n",
    "    pickle.dump(sem_experts, file)\n",
    "\n",
    "with gzip.open('../data/sem_full.pkl', 'wb') as file:\n",
    "    pickle.dump(sem_full, file)\n",
    "\n",
    "with gzip.open('../data/sem_city.pkl', 'wb') as file:\n",
    "    pickle.dump(sem_city, file)"
   ],
   "id": "17fae2483ed7c1c3",
   "outputs": [],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
