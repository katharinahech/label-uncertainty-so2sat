{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:57:11.635067Z",
     "start_time": "2024-07-03T12:57:10.766472Z"
    }
   },
   "source": [
    "from src import sem_functions, city_functions, expert_functions\n",
    "import importlib\n",
    "\n",
    "importlib.reload(sem_functions)\n",
    "\n",
    "from src.sem_functions import *\n",
    "from src.city_functions import *\n",
    "from src.expert_functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T12:57:25.422615Z",
     "start_time": "2024-07-03T12:57:25.201786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import csv \n",
    "\n",
    "cities_one_hot_16 = pd.read_csv('/Users/katharina/Documents/PhD/Data/LCZ_Votes/prepared_datasets/cities_one_hot_16.csv').to_numpy()\n",
    "cities_one_hot_named_16 = pd.read_csv('/Users/katharina/Documents/PhD/Data/LCZ_Votes/prepared_datasets/cities_one_hot_named_16.csv')\n",
    "all_cities_16 = pd.read_csv('/Users/katharina/Documents/PhD/Data/LCZ_Votes/prepared_datasets/all_cities_16.csv').to_numpy()"
   ],
   "id": "c7022303d475a283",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Full Dataset",
   "id": "5e3674e368bef09e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T08:31:36.875434Z",
     "start_time": "2024-07-03T08:23:56.719286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# run sem on full dataset\n",
    "\n",
    "sem_16_full_test = sem_fit_var(cities_one_hot_16, K=16, max_iter=20, rtol=1e-3, restarts=5)"
   ],
   "id": "c321eeec0acf359f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "Loss: -554692.959719\n",
      "Loss: -553292.901320\n",
      "Loss: -552898.686605\n",
      "better loss on iteration 0: -552898.6866052285\n",
      "iteration 1\n",
      "Loss: -554847.659485\n",
      "Loss: -553309.330064\n",
      "Loss: -552911.482924\n",
      "iteration 2\n",
      "Loss: -554657.123919\n",
      "Loss: -553276.522076\n",
      "Loss: -552926.187463\n",
      "iteration 3\n",
      "Loss: -554533.224322\n",
      "Loss: -553312.699214\n",
      "Loss: -552793.304145\n",
      "better loss on iteration 3: -552793.3041453870\n",
      "iteration 4\n",
      "Loss: -554611.424223\n",
      "Loss: -553259.367131\n",
      "Loss: -552820.009658\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T08:32:10.615294Z",
     "start_time": "2024-07-03T08:31:57.575407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# extract parameters\n",
    "\n",
    "pi_full = sem_16_full_test[1]\n",
    "theta_full = sem_16_full_test[2]\n",
    "tau_full = e_step_nozerocorrection(cities_one_hot_16, pi_full, theta_full)"
   ],
   "id": "c92871c7628af2e0",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Per City ",
   "id": "8e7450053f94c627"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T08:33:48.199279Z",
     "start_time": "2024-07-03T08:33:48.195440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "city_list = ['berlin', 'cologne', 'london', 'madrid',\n",
    "             'milan', 'munich', 'paris', 'rome', 'zurich']"
   ],
   "id": "aa5c3eb36ba5d47a",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T08:43:18.745386Z",
     "start_time": "2024-07-03T08:33:54.309965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# run sem for instances from each city separately\n",
    "\n",
    "city_sem_16_original_init_test = [sem_fit_var_per_city(city, data=cities_one_hot_named_16,\n",
    "                                                  K=16, restarts=5, rtol=1e-3, max_iter=20) for city in city_list]"
   ],
   "id": "61160e2eea55843d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "Loss: -84070.413615\n",
      "Loss: -83689.836228\n",
      "Loss: -83566.194985\n",
      "Loss: -83534.285139\n",
      "better loss on iteration 0: -83534.2851388460\n",
      "iteration 1\n",
      "Loss: -84072.365482\n",
      "Loss: -83671.807913\n",
      "Loss: -83550.073861\n",
      "Loss: -83530.998169\n",
      "better loss on iteration 1: -83530.9981691840\n",
      "iteration 2\n",
      "Loss: -84072.370936\n",
      "Loss: -83675.045444\n",
      "Loss: -83559.607301\n",
      "Loss: -83540.942843\n",
      "iteration 3\n",
      "Loss: -84072.150903\n",
      "Loss: -83681.097691\n",
      "Loss: -83575.698673\n",
      "Loss: -83532.008399\n",
      "iteration 4\n",
      "Loss: -84073.778917\n",
      "Loss: -83675.945483\n",
      "Loss: -83566.138182\n",
      "Loss: -83539.806903\n",
      "iteration 0\n",
      "Loss: -66833.315303\n",
      "Loss: -66777.131550\n",
      "Loss: -66744.161690\n",
      "better loss on iteration 0: -66744.1616897858\n",
      "iteration 1\n",
      "Loss: -66835.216212\n",
      "Loss: -66773.894164\n",
      "Loss: -66742.616743\n",
      "better loss on iteration 1: -66742.6167430400\n",
      "iteration 2\n",
      "Loss: -66834.156580\n",
      "Loss: -66773.406281\n",
      "Loss: -66745.861172\n",
      "iteration 3\n",
      "Loss: -66833.059227\n",
      "Loss: -66776.727200\n",
      "Loss: -66744.613374\n",
      "iteration 4\n",
      "Loss: -66833.209911\n",
      "Loss: -66773.910375\n",
      "Loss: -66741.340285\n",
      "better loss on iteration 4: -66741.3402852907\n",
      "iteration 0\n",
      "Loss: -112893.506341\n",
      "Loss: -112874.257411\n",
      "Loss: -112882.876203\n",
      "better loss on iteration 0: -112882.8762031762\n",
      "iteration 1\n",
      "Loss: -112905.551131\n",
      "Loss: -112873.112627\n",
      "Loss: -112868.669777\n",
      "better loss on iteration 1: -112868.6697768531\n",
      "iteration 2\n",
      "Loss: -112892.490603\n",
      "Loss: -112872.901177\n",
      "Loss: -112871.227419\n",
      "iteration 3\n",
      "Loss: -112891.143895\n",
      "Loss: -112874.073479\n",
      "Loss: -112866.981805\n",
      "better loss on iteration 3: -112866.9818052858\n",
      "iteration 4\n",
      "Loss: -112890.768413\n",
      "Loss: -112872.722149\n",
      "Loss: -112882.908868\n",
      "iteration 0\n",
      "Loss: -57440.013479\n",
      "Loss: -57464.318171\n",
      "Loss: -57388.065830\n",
      "Loss: -57457.082323\n",
      "Loss: -57461.062997\n",
      "better loss on iteration 0: -57461.0629974670\n",
      "iteration 1\n",
      "Loss: -57408.609619\n",
      "Loss: -57462.770918\n",
      "Loss: -57436.714694\n",
      "better loss on iteration 1: -57436.7146937707\n",
      "iteration 2\n",
      "Loss: -57465.397261\n",
      "Loss: -57462.589540\n",
      "Loss: -57511.048838\n",
      "iteration 3\n",
      "Loss: -57366.864412\n",
      "Loss: -57396.068440\n",
      "Loss: -57406.966908\n",
      "better loss on iteration 3: -57406.9669080489\n",
      "iteration 4\n",
      "Loss: -57444.736228\n",
      "Loss: -57483.313875\n",
      "Loss: -57482.472307\n",
      "iteration 0\n",
      "Loss: -9088.974053\n",
      "Loss: -9089.801940\n",
      "Loss: -9086.823758\n",
      "better loss on iteration 0: -9086.8237579982\n",
      "iteration 1\n",
      "Loss: -9085.676889\n",
      "Loss: -9084.843944\n",
      "Loss: -9084.476044\n",
      "better loss on iteration 1: -9084.4760440669\n",
      "iteration 2\n",
      "Loss: -9085.226720\n",
      "Loss: -9084.504425\n",
      "Loss: -9088.382489\n",
      "iteration 3\n",
      "Loss: -9086.133265\n",
      "Loss: -9085.738495\n",
      "Loss: -9085.288568\n",
      "iteration 4\n",
      "Loss: -9085.603244\n",
      "Loss: -9086.026671\n",
      "Loss: -9084.574323\n",
      "iteration 0\n",
      "Loss: -31804.347169\n",
      "Loss: -31803.964149\n",
      "Loss: -31803.431231\n",
      "better loss on iteration 0: -31803.4312310057\n",
      "iteration 1\n",
      "Loss: -31804.347169\n",
      "Loss: -31803.964149\n",
      "Loss: -31803.552791\n",
      "iteration 2\n",
      "Loss: -31804.747456\n",
      "Loss: -31804.409963\n",
      "Loss: -31804.152130\n",
      "iteration 3\n",
      "Loss: -31804.728915\n",
      "Loss: -31803.431231\n",
      "Loss: -31802.806358\n",
      "better loss on iteration 3: -31802.8063575296\n",
      "iteration 4\n",
      "Loss: -31804.747456\n",
      "Loss: -31804.728915\n",
      "Loss: -31805.666371\n",
      "iteration 0\n",
      "Loss: -47055.124576\n",
      "Loss: -47169.217147\n",
      "Loss: -47362.922301\n",
      "Loss: -47158.367642\n",
      "Loss: -46906.138407\n",
      "Loss: -47265.088142\n",
      "Loss: -47300.165083\n",
      "better loss on iteration 0: -47300.1650828995\n",
      "iteration 1\n",
      "Loss: -47155.972900\n",
      "Loss: -46760.605911\n",
      "Loss: -47320.149747\n",
      "Loss: -46958.420443\n",
      "Loss: -47206.539125\n",
      "Loss: -47161.894587\n",
      "better loss on iteration 1: -47161.8945865981\n",
      "iteration 2\n",
      "Loss: -47413.695180\n",
      "Loss: -47528.458856\n",
      "Loss: -47091.289970\n",
      "Loss: -47517.023015\n",
      "Loss: -47291.502788\n",
      "Loss: -47509.090878\n",
      "Loss: -47312.597227\n",
      "Loss: -47508.995776\n",
      "Loss: -47176.900184\n",
      "Loss: -47356.362236\n",
      "Loss: -46949.751170\n",
      "Loss: -47436.476385\n",
      "Loss: -47075.249932\n",
      "Loss: -47043.220932\n",
      "better loss on iteration 2: -47043.2209321826\n",
      "iteration 3\n",
      "Loss: -47166.372679\n",
      "Loss: -46908.779491\n",
      "Loss: -47462.615397\n",
      "Loss: -46907.342912\n",
      "Loss: -47242.219971\n",
      "Loss: -47113.900156\n",
      "Loss: -47373.524352\n",
      "Loss: -47088.878839\n",
      "Loss: -46923.345882\n",
      "Loss: -47205.044543\n",
      "Loss: -47066.873905\n",
      "Loss: -47331.622579\n",
      "Loss: -47280.813079\n",
      "Loss: -47144.762615\n",
      "Loss: -47255.099743\n",
      "Loss: -47324.395689\n",
      "Loss: -47262.072954\n",
      "Loss: -47342.878030\n",
      "Loss: -47208.853146\n",
      "Loss: -47102.530437\n",
      "iteration 4\n",
      "Loss: -47104.025388\n",
      "Loss: -47448.782925\n",
      "Loss: -46934.626362\n",
      "Loss: -47279.402872\n",
      "Loss: -47102.698329\n",
      "Loss: -47130.586151\n",
      "iteration 0\n",
      "Loss: -19387.109978\n",
      "Loss: -19345.958469\n",
      "Loss: -19344.704093\n",
      "better loss on iteration 0: -19344.7040926042\n",
      "iteration 1\n",
      "Loss: -19384.526947\n",
      "Loss: -19349.026353\n",
      "Loss: -19347.758004\n",
      "iteration 2\n",
      "Loss: -19382.868857\n",
      "Loss: -19352.521139\n",
      "Loss: -19347.344994\n",
      "iteration 3\n",
      "Loss: -19383.849420\n",
      "Loss: -19346.333926\n",
      "Loss: -19348.128139\n",
      "iteration 4\n",
      "Loss: -19387.690390\n",
      "Loss: -19352.960350\n",
      "Loss: -19347.956541\n",
      "iteration 0\n",
      "Loss: -15021.146744\n",
      "Loss: -15025.791903\n",
      "Loss: -15020.483414\n",
      "better loss on iteration 0: -15020.4834139674\n",
      "iteration 1\n",
      "Loss: -15019.824201\n",
      "Loss: -15005.933977\n",
      "Loss: -15022.342998\n",
      "Loss: -15027.342468\n",
      "iteration 2\n",
      "Loss: -15019.659165\n",
      "Loss: -15024.877536\n",
      "Loss: -15019.055020\n",
      "better loss on iteration 2: -15019.0550204662\n",
      "iteration 3\n",
      "Loss: -15037.953528\n",
      "Loss: -15062.484905\n",
      "Loss: -15038.301706\n",
      "Loss: -15042.944228\n",
      "iteration 4\n",
      "Loss: -15051.157814\n",
      "Loss: -15065.442127\n",
      "Loss: -15027.922965\n",
      "Loss: -15020.903716\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Per Expert",
   "id": "9b03b65d1cc68d37"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T08:44:11.835805Z",
     "start_time": "2024-07-03T08:44:11.751545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create expert-specific dataframes: df_1 -> exclude annotations from expert 1\n",
    "\n",
    "one_hot_experts = expert_data(all_cities_16, cities_one_hot_16)"
   ],
   "id": "171dd1a415aa7fe9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df  0  done.\n",
      "df  1  done.\n",
      "df  2  done.\n",
      "df  3  done.\n",
      "df  4  done.\n",
      "df  5  done.\n",
      "df  6  done.\n",
      "df  7  done.\n",
      "df  8  done.\n",
      "df  9  done.\n",
      "df  10  done.\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T10:04:33.748675Z",
     "start_time": "2024-07-03T08:44:23.652647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# run sem for each expert-specific dataframe \n",
    "\n",
    "sem_16_experts_test = expert_sem(one_hot_experts, K=16, rtol=1e-3, max_iter=20, restarts=5)"
   ],
   "id": "e1bc010f8a836d15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exclude expert  0\n",
      "iteration 0\n",
      "Loss: -524680.556188\n",
      "Loss: -524398.452199\n",
      "better loss on iteration 0: -524398.4521985831\n",
      "iteration 1\n",
      "Loss: -524678.398808\n",
      "Loss: -524324.122668\n",
      "better loss on iteration 1: -524324.1226677628\n",
      "iteration 2\n",
      "Loss: -524666.254358\n",
      "Loss: -524280.444828\n",
      "better loss on iteration 2: -524280.4448276382\n",
      "iteration 3\n",
      "Loss: -524643.111616\n",
      "Loss: -524354.844757\n",
      "iteration 4\n",
      "Loss: -524639.368712\n",
      "Loss: -524329.442623\n",
      "exclude expert  1\n",
      "iteration 0\n",
      "Loss: -541845.859922\n",
      "Loss: -541115.250683\n",
      "Loss: -540984.920661\n",
      "better loss on iteration 0: -540984.9206612571\n",
      "iteration 1\n",
      "Loss: -541933.467656\n",
      "Loss: -541194.567113\n",
      "Loss: -540957.375646\n",
      "better loss on iteration 1: -540957.3756462162\n",
      "iteration 2\n",
      "Loss: -541877.823124\n",
      "Loss: -541228.836166\n",
      "Loss: -540910.242076\n",
      "better loss on iteration 2: -540910.2420758512\n",
      "iteration 3\n",
      "Loss: -541809.627138\n",
      "Loss: -541188.461439\n",
      "Loss: -540931.519075\n",
      "iteration 4\n",
      "Loss: -541954.556513\n",
      "Loss: -541293.191064\n",
      "Loss: -540988.607735\n",
      "exclude expert  2\n",
      "iteration 0\n",
      "Loss: -539079.109250\n",
      "Loss: -538704.513671\n",
      "better loss on iteration 0: -538704.5136712249\n",
      "iteration 1\n",
      "Loss: -539063.671214\n",
      "Loss: -538659.226080\n",
      "better loss on iteration 1: -538659.2260796508\n",
      "iteration 2\n",
      "Loss: -539093.372087\n",
      "Loss: -538638.342178\n",
      "better loss on iteration 2: -538638.3421776888\n",
      "iteration 3\n",
      "Loss: -539104.196871\n",
      "Loss: -538605.703169\n",
      "better loss on iteration 3: -538605.7031687256\n",
      "iteration 4\n",
      "Loss: -539129.236111\n",
      "Loss: -538668.052270\n",
      "exclude expert  3\n",
      "iteration 0\n",
      "Loss: -539260.155852\n",
      "Loss: -538644.420173\n",
      "Loss: -536825.503861\n",
      "Loss: -536010.896156\n",
      "Loss: -535626.469366\n",
      "better loss on iteration 0: -535626.4693664795\n",
      "iteration 1\n",
      "Loss: -539287.917160\n",
      "Loss: -537498.517107\n",
      "Loss: -536269.030313\n",
      "Loss: -535772.008732\n",
      "iteration 2\n",
      "Loss: -539309.705054\n",
      "Loss: -538601.419657\n",
      "Loss: -538274.091142\n",
      "iteration 3\n",
      "Loss: -539363.578991\n",
      "Loss: -538498.592180\n",
      "Loss: -536808.371092\n",
      "Loss: -535968.144280\n",
      "Loss: -535710.940581\n",
      "iteration 4\n",
      "Loss: -539320.126182\n",
      "Loss: -537339.372282\n",
      "Loss: -536230.423755\n",
      "Loss: -535779.539733\n",
      "exclude expert  4\n",
      "iteration 0\n",
      "Loss: -531411.725786\n",
      "Loss: -531040.023194\n",
      "better loss on iteration 0: -531040.0231936666\n",
      "iteration 1\n",
      "Loss: -531395.089166\n",
      "Loss: -531066.909443\n",
      "iteration 2\n",
      "Loss: -531410.897435\n",
      "Loss: -530984.621137\n",
      "better loss on iteration 2: -530984.6211372550\n",
      "iteration 3\n",
      "Loss: -531428.216459\n",
      "Loss: -531042.135639\n",
      "iteration 4\n",
      "Loss: -531393.290731\n",
      "Loss: -531050.625384\n",
      "exclude expert  5\n",
      "iteration 0\n",
      "Loss: -535019.213629\n",
      "Loss: -533757.510084\n",
      "Loss: -533572.497486\n",
      "better loss on iteration 0: -533572.4974859295\n",
      "iteration 1\n",
      "Loss: -535003.829071\n",
      "Loss: -533830.071978\n",
      "Loss: -533546.217274\n",
      "better loss on iteration 1: -533546.2172740549\n",
      "iteration 2\n",
      "Loss: -535100.654827\n",
      "Loss: -533842.552982\n",
      "Loss: -533554.285549\n",
      "iteration 3\n",
      "Loss: -535021.033238\n",
      "Loss: -533825.151635\n",
      "Loss: -533519.941876\n",
      "better loss on iteration 3: -533519.9418764079\n",
      "iteration 4\n",
      "Loss: -534941.520048\n",
      "Loss: -533803.422717\n",
      "Loss: -533469.521281\n",
      "better loss on iteration 4: -533469.5212809753\n",
      "exclude expert  6\n",
      "iteration 0\n",
      "Loss: -535174.697127\n",
      "Loss: -533859.675146\n",
      "Loss: -533495.036162\n",
      "better loss on iteration 0: -533495.0361616522\n",
      "iteration 1\n",
      "Loss: -535183.192564\n",
      "Loss: -533803.703081\n",
      "Loss: -533384.727819\n",
      "better loss on iteration 1: -533384.7278192535\n",
      "iteration 2\n",
      "Loss: -535217.791831\n",
      "Loss: -533852.287192\n",
      "Loss: -533457.652901\n",
      "iteration 3\n",
      "Loss: -535093.087518\n",
      "Loss: -533870.273204\n",
      "Loss: -533522.995458\n",
      "iteration 4\n",
      "Loss: -535192.521879\n",
      "Loss: -533810.618215\n",
      "Loss: -533465.217112\n",
      "exclude expert  7\n",
      "iteration 0\n",
      "Loss: -533309.914059\n",
      "Loss: -532485.840141\n",
      "Loss: -532294.539500\n",
      "better loss on iteration 0: -532294.5395003415\n",
      "iteration 1\n",
      "Loss: -533334.570012\n",
      "Loss: -532470.382221\n",
      "Loss: -532216.717402\n",
      "better loss on iteration 1: -532216.7174023353\n",
      "iteration 2\n",
      "Loss: -533282.538499\n",
      "Loss: -532468.393731\n",
      "Loss: -532321.714937\n",
      "iteration 3\n",
      "Loss: -533280.061014\n",
      "Loss: -532464.973287\n",
      "Loss: -532262.369813\n",
      "iteration 4\n",
      "Loss: -533297.556189\n",
      "Loss: -532433.814392\n",
      "Loss: -532260.003268\n",
      "exclude expert  8\n",
      "iteration 0\n",
      "Loss: -540577.706745\n",
      "Loss: -539863.232741\n",
      "Loss: -539729.161521\n",
      "better loss on iteration 0: -539729.1615208875\n",
      "iteration 1\n",
      "Loss: -540504.287605\n",
      "Loss: -539864.021032\n",
      "Loss: -539723.966490\n",
      "better loss on iteration 1: -539723.9664896078\n",
      "iteration 2\n",
      "Loss: -540634.575283\n",
      "Loss: -538875.079652\n",
      "Loss: -538078.107636\n",
      "Loss: -537873.252252\n",
      "better loss on iteration 2: -537873.2522516645\n",
      "iteration 3\n",
      "Loss: -540524.489776\n",
      "Loss: -539948.426408\n",
      "Loss: -538483.470667\n",
      "Loss: -537974.716077\n",
      "iteration 4\n",
      "Loss: -540515.377070\n",
      "Loss: -538985.363000\n",
      "Loss: -538064.412772\n",
      "Loss: -537881.818507\n",
      "exclude expert  9\n",
      "iteration 0\n",
      "Loss: -537842.595627\n",
      "Loss: -536735.937518\n",
      "Loss: -536605.321774\n",
      "better loss on iteration 0: -536605.3217738041\n",
      "iteration 1\n",
      "Loss: -537894.106338\n",
      "Loss: -536745.724199\n",
      "Loss: -536596.528437\n",
      "better loss on iteration 1: -536596.5284366275\n",
      "iteration 2\n",
      "Loss: -537893.127251\n",
      "Loss: -536705.802301\n",
      "Loss: -536585.393322\n",
      "better loss on iteration 2: -536585.3933215770\n",
      "iteration 3\n",
      "Loss: -537863.107704\n",
      "Loss: -536769.631313\n",
      "Loss: -536587.123534\n",
      "iteration 4\n",
      "Loss: -537854.551579\n",
      "Loss: -536743.245220\n",
      "Loss: -536590.206527\n",
      "exclude expert  10\n",
      "iteration 0\n",
      "Loss: -540307.502321\n",
      "Loss: -538893.947856\n",
      "Loss: -538810.155155\n",
      "better loss on iteration 0: -538810.1551553773\n",
      "iteration 1\n",
      "Loss: -540254.959662\n",
      "Loss: -538885.547214\n",
      "Loss: -538684.247104\n",
      "better loss on iteration 1: -538684.2471038871\n",
      "iteration 2\n",
      "Loss: -540350.166950\n",
      "Loss: -538930.940937\n",
      "Loss: -538706.989053\n",
      "iteration 3\n",
      "Loss: -540344.274751\n",
      "Loss: -538854.216188\n",
      "Loss: -538666.087423\n",
      "better loss on iteration 3: -538666.0874232530\n",
      "iteration 4\n",
      "Loss: -540435.772915\n",
      "Loss: -538867.368669\n",
      "Loss: -538811.336166\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T10:07:12.822344Z",
     "start_time": "2024-07-03T10:05:02.110353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save results to lists\n",
    "\n",
    "pi_experts=[]\n",
    "theta_experts=[]\n",
    "tau_experts_org=[]\n",
    "tau_experts=[]\n",
    "\n",
    "j=0\n",
    "for sem in sem_16_experts_test:\n",
    "    pi_experts.append(sem[1])\n",
    "    theta_experts.append(sem[2])\n",
    "    tau_experts_org.append(sem[4])\n",
    "    tau_experts.append(e_step_nozerocorrection(one_hot_experts[j], sem[1], sem[2]))\n",
    "    j=j+1"
   ],
   "id": "dca4fd26398e6402",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T10:12:36.988225Z",
     "start_time": "2024-07-03T10:12:36.910967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save results to pickle \n",
    "\n",
    "with open('/Users/katharina/Documents/PhD/Data/LCZ_Votes/pickle_objects/sem_16_experts_test.pkl', 'wb') as file:\n",
    "    pickle.dump(sem_16_experts_test, file)\n",
    "\n",
    "with open('/Users/katharina/Documents/PhD/Data/LCZ_Votes/pickle_objects/sem_16_full_test.pkl', 'wb') as file:\n",
    "    pickle.dump(sem_16_full_test, file)\n",
    "\n",
    "with open('/Users/katharina/Documents/PhD/Data/LCZ_Votes/pickle_objects/city_sem_16_original_init_test.pkl', 'wb') as file:\n",
    "    pickle.dump(city_sem_16_original_init_test, file)"
   ],
   "id": "17fae2483ed7c1c3",
   "outputs": [],
   "execution_count": 95
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
